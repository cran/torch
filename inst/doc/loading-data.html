<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />

<meta name="viewport" content="width=device-width, initial-scale=1" />



<title>Loading data</title>

<script>// Pandoc 2.9 adds attributes on both header and div. We remove the former (to
// be compatible with the behavior of Pandoc < 2.8).
document.addEventListener('DOMContentLoaded', function(e) {
  var hs = document.querySelectorAll("div.section[class*='level'] > :first-child");
  var i, h, a;
  for (i = 0; i < hs.length; i++) {
    h = hs[i];
    if (!/^h[1-6]$/i.test(h.tagName)) continue;  // it should be a header h1-h6
    a = h.attributes;
    while (a.length > 0) h.removeAttribute(a[0].name);
  }
});
</script>

<style type="text/css">
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
span.underline{text-decoration: underline;}
div.column{display: inline-block; vertical-align: top; width: 50%;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
</style>



<style type="text/css">
code {
white-space: pre;
}
.sourceCode {
overflow: visible;
}
</style>
<style type="text/css" data-origin="pandoc">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
{ counter-reset: source-line 0; }
pre.numberSource code > span
{ position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
{ content: counter(source-line);
position: relative; left: -1em; text-align: right; vertical-align: baseline;
border: none; display: inline-block;
-webkit-touch-callout: none; -webkit-user-select: none;
-khtml-user-select: none; -moz-user-select: none;
-ms-user-select: none; user-select: none;
padding: 0 4px; width: 4em;
color: #aaaaaa;
}
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa; padding-left: 4px; }
div.sourceCode
{ }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } 
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } 
code span.at { color: #7d9029; } 
code span.bn { color: #40a070; } 
code span.bu { color: #008000; } 
code span.cf { color: #007020; font-weight: bold; } 
code span.ch { color: #4070a0; } 
code span.cn { color: #880000; } 
code span.co { color: #60a0b0; font-style: italic; } 
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } 
code span.do { color: #ba2121; font-style: italic; } 
code span.dt { color: #902000; } 
code span.dv { color: #40a070; } 
code span.er { color: #ff0000; font-weight: bold; } 
code span.ex { } 
code span.fl { color: #40a070; } 
code span.fu { color: #06287e; } 
code span.im { color: #008000; font-weight: bold; } 
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } 
code span.kw { color: #007020; font-weight: bold; } 
code span.op { color: #666666; } 
code span.ot { color: #007020; } 
code span.pp { color: #bc7a00; } 
code span.sc { color: #4070a0; } 
code span.ss { color: #bb6688; } 
code span.st { color: #4070a0; } 
code span.va { color: #19177c; } 
code span.vs { color: #4070a0; } 
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } 
</style>
<script>
// apply pandoc div.sourceCode style to pre.sourceCode instead
(function() {
  var sheets = document.styleSheets;
  for (var i = 0; i < sheets.length; i++) {
    if (sheets[i].ownerNode.dataset["origin"] !== "pandoc") continue;
    try { var rules = sheets[i].cssRules; } catch (e) { continue; }
    var j = 0;
    while (j < rules.length) {
      var rule = rules[j];
      // check if there is a div.sourceCode rule
      if (rule.type !== rule.STYLE_RULE || rule.selectorText !== "div.sourceCode") {
        j++;
        continue;
      }
      var style = rule.style.cssText;
      // check if color or background-color is set
      if (rule.style.color === '' && rule.style.backgroundColor === '') {
        j++;
        continue;
      }
      // replace div.sourceCode by a pre.sourceCode rule
      sheets[i].deleteRule(j);
      sheets[i].insertRule('pre.sourceCode{' + style + '}', j);
    }
  }
})();
</script>




<style type="text/css">body {
background-color: #fff;
margin: 1em auto;
max-width: 700px;
overflow: visible;
padding-left: 2em;
padding-right: 2em;
font-family: "Open Sans", "Helvetica Neue", Helvetica, Arial, sans-serif;
font-size: 14px;
line-height: 1.35;
}
#TOC {
clear: both;
margin: 0 0 10px 10px;
padding: 4px;
width: 400px;
border: 1px solid #CCCCCC;
border-radius: 5px;
background-color: #f6f6f6;
font-size: 13px;
line-height: 1.3;
}
#TOC .toctitle {
font-weight: bold;
font-size: 15px;
margin-left: 5px;
}
#TOC ul {
padding-left: 40px;
margin-left: -1.5em;
margin-top: 5px;
margin-bottom: 5px;
}
#TOC ul ul {
margin-left: -2em;
}
#TOC li {
line-height: 16px;
}
table {
margin: 1em auto;
border-width: 1px;
border-color: #DDDDDD;
border-style: outset;
border-collapse: collapse;
}
table th {
border-width: 2px;
padding: 5px;
border-style: inset;
}
table td {
border-width: 1px;
border-style: inset;
line-height: 18px;
padding: 5px 5px;
}
table, table th, table td {
border-left-style: none;
border-right-style: none;
}
table thead, table tr.even {
background-color: #f7f7f7;
}
p {
margin: 0.5em 0;
}
blockquote {
background-color: #f6f6f6;
padding: 0.25em 0.75em;
}
hr {
border-style: solid;
border: none;
border-top: 1px solid #777;
margin: 28px 0;
}
dl {
margin-left: 0;
}
dl dd {
margin-bottom: 13px;
margin-left: 13px;
}
dl dt {
font-weight: bold;
}
ul {
margin-top: 0;
}
ul li {
list-style: circle outside;
}
ul ul {
margin-bottom: 0;
}
pre, code {
background-color: #f7f7f7;
border-radius: 3px;
color: #333;
white-space: pre-wrap; 
}
pre {
border-radius: 3px;
margin: 5px 0px 10px 0px;
padding: 10px;
}
pre:not([class]) {
background-color: #f7f7f7;
}
code {
font-family: Consolas, Monaco, 'Courier New', monospace;
font-size: 85%;
}
p > code, li > code {
padding: 2px 0px;
}
div.figure {
text-align: center;
}
img {
background-color: #FFFFFF;
padding: 2px;
border: 1px solid #DDDDDD;
border-radius: 3px;
border: 1px solid #CCCCCC;
margin: 0 5px;
}
h1 {
margin-top: 0;
font-size: 35px;
line-height: 40px;
}
h2 {
border-bottom: 4px solid #f7f7f7;
padding-top: 10px;
padding-bottom: 2px;
font-size: 145%;
}
h3 {
border-bottom: 2px solid #f7f7f7;
padding-top: 10px;
font-size: 120%;
}
h4 {
border-bottom: 1px solid #f7f7f7;
margin-left: 8px;
font-size: 105%;
}
h5, h6 {
border-bottom: 1px solid #ccc;
font-size: 105%;
}
a {
color: #0033dd;
text-decoration: none;
}
a:hover {
color: #6666ff; }
a:visited {
color: #800080; }
a:visited:hover {
color: #BB00BB; }
a[href^="http:"] {
text-decoration: underline; }
a[href^="https:"] {
text-decoration: underline; }

code > span.kw { color: #555; font-weight: bold; } 
code > span.dt { color: #902000; } 
code > span.dv { color: #40a070; } 
code > span.bn { color: #d14; } 
code > span.fl { color: #d14; } 
code > span.ch { color: #d14; } 
code > span.st { color: #d14; } 
code > span.co { color: #888888; font-style: italic; } 
code > span.ot { color: #007020; } 
code > span.al { color: #ff0000; font-weight: bold; } 
code > span.fu { color: #900; font-weight: bold; } 
code > span.er { color: #a61717; background-color: #e3d2d2; } 
</style>




</head>

<body>




<h1 class="title toc-ignore">Loading data</h1>



<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" tabindex="-1"></a><span class="fu">library</span>(torch)</span></code></pre></div>
<div id="datasets-and-data-loaders" class="section level2">
<h2>Datasets and data loaders</h2>
<p>Central to data ingestion and preprocessing are datasets and data
loaders. A dataset is an object that holds the data to use, while a data
loader is an object that will load the data from a dataset providing a
way to access subsets of the data. By using datasets and data loaders
you will have a process for clearly organizing your data and passing it
to other components of the torch package, such as model training.</p>
<p>Built into <code>torch</code> are premade datasets that are commonly
used in machine learning, such as the MNIST handwriting dataset
(<code>mnist_dataset()</code>). Most of the prebuilt datasets relate to
image recognition and natural language processing.</p>
<p>Below is an example of how you would use the MNIST dataset with a
dataloader. First, the <code>minst_dataset()</code> function is used to
create <code>ds</code> which is a <code>Dataset</code> object. Then a
dataloader <code>dl</code> is created to query that data. Finally, that
dataloader is used in a <code>coro::loop()</code> to iterate over
batches of that data:</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" tabindex="-1"></a><span class="co"># Create a dataset from included data</span></span>
<span id="cb2-2"><a href="#cb2-2" tabindex="-1"></a>ds <span class="ot">&lt;-</span> <span class="fu">mnist_dataset</span>(</span>
<span id="cb2-3"><a href="#cb2-3" tabindex="-1"></a>  dir, </span>
<span id="cb2-4"><a href="#cb2-4" tabindex="-1"></a>  <span class="at">download =</span> <span class="cn">TRUE</span>, </span>
<span id="cb2-5"><a href="#cb2-5" tabindex="-1"></a>  <span class="at">transform =</span> <span class="cf">function</span>(x) {</span>
<span id="cb2-6"><a href="#cb2-6" tabindex="-1"></a>    x <span class="ot">&lt;-</span> x<span class="sc">$</span><span class="fu">to</span>(<span class="at">dtype =</span> <span class="fu">torch_float</span>())<span class="sc">/</span><span class="dv">256</span></span>
<span id="cb2-7"><a href="#cb2-7" tabindex="-1"></a>    x[newaxis,..]</span>
<span id="cb2-8"><a href="#cb2-8" tabindex="-1"></a>  }</span>
<span id="cb2-9"><a href="#cb2-9" tabindex="-1"></a>)</span>
<span id="cb2-10"><a href="#cb2-10" tabindex="-1"></a></span>
<span id="cb2-11"><a href="#cb2-11" tabindex="-1"></a><span class="co"># Create the loader to query the data in batches</span></span>
<span id="cb2-12"><a href="#cb2-12" tabindex="-1"></a>dl <span class="ot">&lt;-</span> <span class="fu">dataloader</span>(ds, <span class="at">batch_size =</span> <span class="dv">32</span>, <span class="at">shuffle =</span> <span class="cn">TRUE</span>)</span>
<span id="cb2-13"><a href="#cb2-13" tabindex="-1"></a></span>
<span id="cb2-14"><a href="#cb2-14" tabindex="-1"></a>coro<span class="sc">::</span><span class="fu">loop</span>(<span class="cf">for</span> (b <span class="cf">in</span> dl)) {</span>
<span id="cb2-15"><a href="#cb2-15" tabindex="-1"></a><span class="co"># use the data from each batch `b` here</span></span>
<span id="cb2-16"><a href="#cb2-16" tabindex="-1"></a><span class="co"># ...</span></span>
<span id="cb2-17"><a href="#cb2-17" tabindex="-1"></a>}<span class="er">)</span></span></code></pre></div>
<p>See <code>vignettes/examples/mnist-cnn.R</code> for a complete
example.</p>
<p>In the more common situation where you have a unique set of data that
isn’t included with the package you’ll need to make a custom
<code>Dataset</code> subclass by using the <code>dataset()</code>
function. The custom <code>Dataset</code> subclass is an abstract R6
container for the data. It will need to know some information about the
particular dataset, such as how to iterate over it.</p>
<p>At a minimum, when using <code>dataset()</code> to create a custom
<code>Dataset</code> class you’ll want to define the following:</p>
<ul>
<li><code>name</code> - for convenience, keep track of what type of data
it is</li>
<li><code>initialize</code> - a member function defining how to create a
object with that class. It could have no parameters, for when all
objects of that class will be the same, or you can give it specific
parameters usually for if different objects should have different
data.</li>
<li><code>.getitem</code> - this member function is called when the
dataloader goes to pull a new batch of data. You can include
preprocessing in this function if needed. Note that the function will be
called extremely frequently, so it’s advantageous to make it fast.</li>
<li><code>.length</code> - this will return the amount of data in the
dataset, which is helpful for users.</li>
</ul>
</div>
<div id="example-of-using-a-custom-dataset" class="section level2">
<h2>Example of using a custom Dataset</h2>
<p>While this may sound complicated the base logic is only a few
steps–the complexity often comes from the data itself and how involved
your preprocessing is. Here we show how to create your own
<code>Dataset</code> class to train on <a href="https://github.com/allisonhorst/palmerpenguins">Allison Horst&#39;s
penguins</a>.</p>
<table style="width:100%;">
<colgroup>
<col width="16%" />
<col width="35%" />
<col width="16%" />
<col width="16%" />
<col width="16%" />
</colgroup>
<thead>
<tr class="header">
<th align="left">Component</th>
<th align="center"><code>Dataset</code> R6 class</th>
<th align="center"><code>Dataset</code> object</th>
<th align="center"><code>DataLoader</code> object</th>
<th align="center">batch</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Description</td>
<td align="center">Output of <code>dataset()</code>. When calling
<code>dataset()</code> it should have at least a <code>name</code>,
<code>initialize</code>, <code>.getitem</code>, and
<code>.length</code>. Output is a <code>Dataset</code> generator.</td>
<td align="center">Object created by using the custom
<code>Dataset</code> generator. Actually stores the data</td>
<td align="center">Object that queries the <code>Dataset</code> object
to pull batches of data</td>
<td align="center">The subsample of data used for things like model
training</td>
</tr>
<tr class="even">
<td align="left">Penguin example</td>
<td align="center"><code>penguins_dataset</code></td>
<td align="center"><code>tuxes</code></td>
<td align="center"><code>dl</code></td>
<td align="center"><code>b</code></td>
</tr>
</tbody>
</table>
<div class="sourceCode" id="cb3"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" tabindex="-1"></a><span class="fu">library</span>(palmerpenguins)</span>
<span id="cb3-2"><a href="#cb3-2" tabindex="-1"></a><span class="fu">library</span>(magrittr)</span>
<span id="cb3-3"><a href="#cb3-3" tabindex="-1"></a></span>
<span id="cb3-4"><a href="#cb3-4" tabindex="-1"></a>penguins</span>
<span id="cb3-5"><a href="#cb3-5" tabindex="-1"></a><span class="co">#&gt; # A tibble: 344 × 8</span></span>
<span id="cb3-6"><a href="#cb3-6" tabindex="-1"></a><span class="co">#&gt;    species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g</span></span>
<span id="cb3-7"><a href="#cb3-7" tabindex="-1"></a><span class="co">#&gt;    &lt;fct&gt;   &lt;fct&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;</span></span>
<span id="cb3-8"><a href="#cb3-8" tabindex="-1"></a><span class="co">#&gt;  1 Adelie  Torgersen           39.1          18.7               181        3750</span></span>
<span id="cb3-9"><a href="#cb3-9" tabindex="-1"></a><span class="co">#&gt;  2 Adelie  Torgersen           39.5          17.4               186        3800</span></span>
<span id="cb3-10"><a href="#cb3-10" tabindex="-1"></a><span class="co">#&gt;  3 Adelie  Torgersen           40.3          18                 195        3250</span></span>
<span id="cb3-11"><a href="#cb3-11" tabindex="-1"></a><span class="co">#&gt;  4 Adelie  Torgersen           NA            NA                  NA          NA</span></span>
<span id="cb3-12"><a href="#cb3-12" tabindex="-1"></a><span class="co">#&gt;  5 Adelie  Torgersen           36.7          19.3               193        3450</span></span>
<span id="cb3-13"><a href="#cb3-13" tabindex="-1"></a><span class="co">#&gt;  6 Adelie  Torgersen           39.3          20.6               190        3650</span></span>
<span id="cb3-14"><a href="#cb3-14" tabindex="-1"></a><span class="co">#&gt;  7 Adelie  Torgersen           38.9          17.8               181        3625</span></span>
<span id="cb3-15"><a href="#cb3-15" tabindex="-1"></a><span class="co">#&gt;  8 Adelie  Torgersen           39.2          19.6               195        4675</span></span>
<span id="cb3-16"><a href="#cb3-16" tabindex="-1"></a><span class="co">#&gt;  9 Adelie  Torgersen           34.1          18.1               193        3475</span></span>
<span id="cb3-17"><a href="#cb3-17" tabindex="-1"></a><span class="co">#&gt; 10 Adelie  Torgersen           42            20.2               190        4250</span></span>
<span id="cb3-18"><a href="#cb3-18" tabindex="-1"></a><span class="co">#&gt; # ℹ 334 more rows</span></span>
<span id="cb3-19"><a href="#cb3-19" tabindex="-1"></a><span class="co">#&gt; # ℹ 2 more variables: sex &lt;fct&gt;, year &lt;int&gt;</span></span></code></pre></div>
<p>In addition, any number of helper functions can be defined.</p>
<p>Here, we assume the <code>penguins</code> have already been loaded,
and all preprocessing consists in removing lines with <code>NA</code>
values, transforming <code>factor</code>s to numbers starting from 0,
and converting from R data types to <code>torch</code> tensors.</p>
<p>In <code>.getitem</code>, we essentially decide how this data is
going to be used: All variables besides <code>species</code> go into
<code>x</code>, the predictor, and <code>species</code> will constitute
<code>y</code>, the target. Predictor and target are returned in a list,
to be accessed as <code>batch[[1]]</code> and <code>batch[[2]]</code>
during training.</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb4-1"><a href="#cb4-1" tabindex="-1"></a>penguins_dataset <span class="ot">&lt;-</span> <span class="fu">dataset</span>(</span>
<span id="cb4-2"><a href="#cb4-2" tabindex="-1"></a>  </span>
<span id="cb4-3"><a href="#cb4-3" tabindex="-1"></a>  <span class="at">name =</span> <span class="st">&quot;penguins_dataset&quot;</span>,</span>
<span id="cb4-4"><a href="#cb4-4" tabindex="-1"></a>  </span>
<span id="cb4-5"><a href="#cb4-5" tabindex="-1"></a>  <span class="at">initialize =</span> <span class="cf">function</span>() {</span>
<span id="cb4-6"><a href="#cb4-6" tabindex="-1"></a>    self<span class="sc">$</span>data <span class="ot">&lt;-</span> self<span class="sc">$</span><span class="fu">prepare_penguin_data</span>()</span>
<span id="cb4-7"><a href="#cb4-7" tabindex="-1"></a>  },</span>
<span id="cb4-8"><a href="#cb4-8" tabindex="-1"></a>  </span>
<span id="cb4-9"><a href="#cb4-9" tabindex="-1"></a>  <span class="at">.getitem =</span> <span class="cf">function</span>(index) {</span>
<span id="cb4-10"><a href="#cb4-10" tabindex="-1"></a>    </span>
<span id="cb4-11"><a href="#cb4-11" tabindex="-1"></a>    x <span class="ot">&lt;-</span> self<span class="sc">$</span>data[index, <span class="dv">2</span><span class="sc">:-</span><span class="dv">1</span>]</span>
<span id="cb4-12"><a href="#cb4-12" tabindex="-1"></a>    y <span class="ot">&lt;-</span> self<span class="sc">$</span>data[index, <span class="dv">1</span>]<span class="sc">$</span><span class="fu">to</span>(<span class="fu">torch_long</span>())</span>
<span id="cb4-13"><a href="#cb4-13" tabindex="-1"></a>    </span>
<span id="cb4-14"><a href="#cb4-14" tabindex="-1"></a>    <span class="fu">list</span>(x, y)</span>
<span id="cb4-15"><a href="#cb4-15" tabindex="-1"></a>  },</span>
<span id="cb4-16"><a href="#cb4-16" tabindex="-1"></a>  </span>
<span id="cb4-17"><a href="#cb4-17" tabindex="-1"></a>  <span class="at">.length =</span> <span class="cf">function</span>() {</span>
<span id="cb4-18"><a href="#cb4-18" tabindex="-1"></a>    self<span class="sc">$</span>data<span class="sc">$</span><span class="fu">size</span>()[[<span class="dv">1</span>]]</span>
<span id="cb4-19"><a href="#cb4-19" tabindex="-1"></a>  },</span>
<span id="cb4-20"><a href="#cb4-20" tabindex="-1"></a>  </span>
<span id="cb4-21"><a href="#cb4-21" tabindex="-1"></a>  <span class="at">prepare_penguin_data =</span> <span class="cf">function</span>() {</span>
<span id="cb4-22"><a href="#cb4-22" tabindex="-1"></a>    </span>
<span id="cb4-23"><a href="#cb4-23" tabindex="-1"></a>    input <span class="ot">&lt;-</span> <span class="fu">na.omit</span>(penguins) </span>
<span id="cb4-24"><a href="#cb4-24" tabindex="-1"></a>    <span class="co"># conveniently, the categorical data are already factors</span></span>
<span id="cb4-25"><a href="#cb4-25" tabindex="-1"></a>    input<span class="sc">$</span>species <span class="ot">&lt;-</span> <span class="fu">as.numeric</span>(input<span class="sc">$</span>species)</span>
<span id="cb4-26"><a href="#cb4-26" tabindex="-1"></a>    input<span class="sc">$</span>island <span class="ot">&lt;-</span> <span class="fu">as.numeric</span>(input<span class="sc">$</span>island)</span>
<span id="cb4-27"><a href="#cb4-27" tabindex="-1"></a>    input<span class="sc">$</span>sex <span class="ot">&lt;-</span> <span class="fu">as.numeric</span>(input<span class="sc">$</span>sex)</span>
<span id="cb4-28"><a href="#cb4-28" tabindex="-1"></a>    </span>
<span id="cb4-29"><a href="#cb4-29" tabindex="-1"></a>    input <span class="ot">&lt;-</span> <span class="fu">as.matrix</span>(input)</span>
<span id="cb4-30"><a href="#cb4-30" tabindex="-1"></a>    <span class="fu">torch_tensor</span>(input)</span>
<span id="cb4-31"><a href="#cb4-31" tabindex="-1"></a>  }</span>
<span id="cb4-32"><a href="#cb4-32" tabindex="-1"></a>)</span></code></pre></div>
<p>Let’s create the dataset , query for it’s length, and look at its
first item:</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1" tabindex="-1"></a>tuxes <span class="ot">&lt;-</span> <span class="fu">penguins_dataset</span>()</span>
<span id="cb5-2"><a href="#cb5-2" tabindex="-1"></a>tuxes<span class="sc">$</span><span class="fu">.length</span>()</span>
<span id="cb5-3"><a href="#cb5-3" tabindex="-1"></a><span class="co">#&gt; [1] 333</span></span>
<span id="cb5-4"><a href="#cb5-4" tabindex="-1"></a>tuxes<span class="sc">$</span><span class="fu">.getitem</span>(<span class="dv">1</span>)</span>
<span id="cb5-5"><a href="#cb5-5" tabindex="-1"></a><span class="co">#&gt; [[1]]</span></span>
<span id="cb5-6"><a href="#cb5-6" tabindex="-1"></a><span class="co">#&gt; torch_tensor</span></span>
<span id="cb5-7"><a href="#cb5-7" tabindex="-1"></a><span class="co">#&gt;     3.0000</span></span>
<span id="cb5-8"><a href="#cb5-8" tabindex="-1"></a><span class="co">#&gt;    39.1000</span></span>
<span id="cb5-9"><a href="#cb5-9" tabindex="-1"></a><span class="co">#&gt;    18.7000</span></span>
<span id="cb5-10"><a href="#cb5-10" tabindex="-1"></a><span class="co">#&gt;   181.0000</span></span>
<span id="cb5-11"><a href="#cb5-11" tabindex="-1"></a><span class="co">#&gt;  3750.0000</span></span>
<span id="cb5-12"><a href="#cb5-12" tabindex="-1"></a><span class="co">#&gt;     2.0000</span></span>
<span id="cb5-13"><a href="#cb5-13" tabindex="-1"></a><span class="co">#&gt;  2007.0000</span></span>
<span id="cb5-14"><a href="#cb5-14" tabindex="-1"></a><span class="co">#&gt; [ CPUFloatType{7} ]</span></span>
<span id="cb5-15"><a href="#cb5-15" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb5-16"><a href="#cb5-16" tabindex="-1"></a><span class="co">#&gt; [[2]]</span></span>
<span id="cb5-17"><a href="#cb5-17" tabindex="-1"></a><span class="co">#&gt; torch_tensor</span></span>
<span id="cb5-18"><a href="#cb5-18" tabindex="-1"></a><span class="co">#&gt; 1</span></span>
<span id="cb5-19"><a href="#cb5-19" tabindex="-1"></a><span class="co">#&gt; [ CPULongType{} ]</span></span></code></pre></div>
<p>To be able to iterate over <code>tuxes</code>, we need a data loader
(we override the default batch size of <code>1</code>):</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb6-1"><a href="#cb6-1" tabindex="-1"></a>dl <span class="ot">&lt;-</span> tuxes <span class="sc">%&gt;%</span> <span class="fu">dataloader</span>(<span class="at">batch_size =</span> <span class="dv">8</span>)</span></code></pre></div>
<p>Calling <code>.length()</code> on a data loader (as opposed to a
dataset) will return the number of <code>batches</code> we have:</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb7-1"><a href="#cb7-1" tabindex="-1"></a>dl<span class="sc">$</span><span class="fu">.length</span>()</span>
<span id="cb7-2"><a href="#cb7-2" tabindex="-1"></a><span class="co">#&gt; [1] 42</span></span></code></pre></div>
<p>And we can create an iterator to inspect the first batch:</p>
<div class="sourceCode" id="cb8"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb8-1"><a href="#cb8-1" tabindex="-1"></a>iter <span class="ot">&lt;-</span> dl<span class="sc">$</span><span class="fu">.iter</span>()</span>
<span id="cb8-2"><a href="#cb8-2" tabindex="-1"></a>b <span class="ot">&lt;-</span> iter<span class="sc">$</span><span class="fu">.next</span>()</span>
<span id="cb8-3"><a href="#cb8-3" tabindex="-1"></a>b</span>
<span id="cb8-4"><a href="#cb8-4" tabindex="-1"></a><span class="co">#&gt; [[1]]</span></span>
<span id="cb8-5"><a href="#cb8-5" tabindex="-1"></a><span class="co">#&gt; torch_tensor</span></span>
<span id="cb8-6"><a href="#cb8-6" tabindex="-1"></a><span class="co">#&gt;     3.0000    39.1000    18.7000   181.0000  3750.0000     2.0000  2007.0000</span></span>
<span id="cb8-7"><a href="#cb8-7" tabindex="-1"></a><span class="co">#&gt;     3.0000    39.5000    17.4000   186.0000  3800.0000     1.0000  2007.0000</span></span>
<span id="cb8-8"><a href="#cb8-8" tabindex="-1"></a><span class="co">#&gt;     3.0000    40.3000    18.0000   195.0000  3250.0000     1.0000  2007.0000</span></span>
<span id="cb8-9"><a href="#cb8-9" tabindex="-1"></a><span class="co">#&gt;     3.0000    36.7000    19.3000   193.0000  3450.0000     1.0000  2007.0000</span></span>
<span id="cb8-10"><a href="#cb8-10" tabindex="-1"></a><span class="co">#&gt;     3.0000    39.3000    20.6000   190.0000  3650.0000     2.0000  2007.0000</span></span>
<span id="cb8-11"><a href="#cb8-11" tabindex="-1"></a><span class="co">#&gt;     3.0000    38.9000    17.8000   181.0000  3625.0000     1.0000  2007.0000</span></span>
<span id="cb8-12"><a href="#cb8-12" tabindex="-1"></a><span class="co">#&gt;     3.0000    39.2000    19.6000   195.0000  4675.0000     2.0000  2007.0000</span></span>
<span id="cb8-13"><a href="#cb8-13" tabindex="-1"></a><span class="co">#&gt;     3.0000    41.1000    17.6000   182.0000  3200.0000     1.0000  2007.0000</span></span>
<span id="cb8-14"><a href="#cb8-14" tabindex="-1"></a><span class="co">#&gt; [ CPUFloatType{8,7} ]</span></span>
<span id="cb8-15"><a href="#cb8-15" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb8-16"><a href="#cb8-16" tabindex="-1"></a><span class="co">#&gt; [[2]]</span></span>
<span id="cb8-17"><a href="#cb8-17" tabindex="-1"></a><span class="co">#&gt; torch_tensor</span></span>
<span id="cb8-18"><a href="#cb8-18" tabindex="-1"></a><span class="co">#&gt;  1</span></span>
<span id="cb8-19"><a href="#cb8-19" tabindex="-1"></a><span class="co">#&gt;  1</span></span>
<span id="cb8-20"><a href="#cb8-20" tabindex="-1"></a><span class="co">#&gt;  1</span></span>
<span id="cb8-21"><a href="#cb8-21" tabindex="-1"></a><span class="co">#&gt;  1</span></span>
<span id="cb8-22"><a href="#cb8-22" tabindex="-1"></a><span class="co">#&gt;  1</span></span>
<span id="cb8-23"><a href="#cb8-23" tabindex="-1"></a><span class="co">#&gt;  1</span></span>
<span id="cb8-24"><a href="#cb8-24" tabindex="-1"></a><span class="co">#&gt;  1</span></span>
<span id="cb8-25"><a href="#cb8-25" tabindex="-1"></a><span class="co">#&gt;  1</span></span>
<span id="cb8-26"><a href="#cb8-26" tabindex="-1"></a><span class="co">#&gt; [ CPULongType{8} ]</span></span></code></pre></div>
<p>To train a network, we can use <code>coro::loop()</code> to iterate
over batches.</p>
<div id="training-with-data-loaders" class="section level3">
<h3>Training with data loaders</h3>
<p>Our example network is very simple. (In reality, we would want to
treat <code>island</code> as the categorical variable it is, and either
one-hot-encode or embed it.)</p>
<div class="sourceCode" id="cb9"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb9-1"><a href="#cb9-1" tabindex="-1"></a>net <span class="ot">&lt;-</span> <span class="fu">nn_module</span>(</span>
<span id="cb9-2"><a href="#cb9-2" tabindex="-1"></a>  <span class="st">&quot;PenguinNet&quot;</span>,</span>
<span id="cb9-3"><a href="#cb9-3" tabindex="-1"></a>  <span class="at">initialize =</span> <span class="cf">function</span>() {</span>
<span id="cb9-4"><a href="#cb9-4" tabindex="-1"></a>    self<span class="sc">$</span>fc1 <span class="ot">&lt;-</span> <span class="fu">nn_linear</span>(<span class="dv">7</span>, <span class="dv">32</span>)</span>
<span id="cb9-5"><a href="#cb9-5" tabindex="-1"></a>    self<span class="sc">$</span>fc2 <span class="ot">&lt;-</span> <span class="fu">nn_linear</span>(<span class="dv">32</span>, <span class="dv">3</span>)</span>
<span id="cb9-6"><a href="#cb9-6" tabindex="-1"></a>  },</span>
<span id="cb9-7"><a href="#cb9-7" tabindex="-1"></a>  <span class="at">forward =</span> <span class="cf">function</span>(x) {</span>
<span id="cb9-8"><a href="#cb9-8" tabindex="-1"></a>    x <span class="sc">%&gt;%</span> </span>
<span id="cb9-9"><a href="#cb9-9" tabindex="-1"></a>      self<span class="sc">$</span><span class="fu">fc1</span>() <span class="sc">%&gt;%</span> </span>
<span id="cb9-10"><a href="#cb9-10" tabindex="-1"></a>      <span class="fu">nnf_relu</span>() <span class="sc">%&gt;%</span> </span>
<span id="cb9-11"><a href="#cb9-11" tabindex="-1"></a>      self<span class="sc">$</span><span class="fu">fc2</span>() <span class="sc">%&gt;%</span> </span>
<span id="cb9-12"><a href="#cb9-12" tabindex="-1"></a>      <span class="fu">nnf_log_softmax</span>(<span class="at">dim =</span> <span class="dv">1</span>)</span>
<span id="cb9-13"><a href="#cb9-13" tabindex="-1"></a>  }</span>
<span id="cb9-14"><a href="#cb9-14" tabindex="-1"></a>)</span>
<span id="cb9-15"><a href="#cb9-15" tabindex="-1"></a></span>
<span id="cb9-16"><a href="#cb9-16" tabindex="-1"></a>model <span class="ot">&lt;-</span> <span class="fu">net</span>()</span></code></pre></div>
<p>We still need an optimizer:</p>
<div class="sourceCode" id="cb10"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb10-1"><a href="#cb10-1" tabindex="-1"></a>optimizer <span class="ot">&lt;-</span> <span class="fu">optim_sgd</span>(model<span class="sc">$</span>parameters, <span class="at">lr =</span> <span class="fl">0.01</span>)</span></code></pre></div>
<p>And we’re ready to train:</p>
<div class="sourceCode" id="cb11"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb11-1"><a href="#cb11-1" tabindex="-1"></a><span class="cf">for</span> (epoch <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">10</span>) {</span>
<span id="cb11-2"><a href="#cb11-2" tabindex="-1"></a>  </span>
<span id="cb11-3"><a href="#cb11-3" tabindex="-1"></a>  l <span class="ot">&lt;-</span> <span class="fu">c</span>()</span>
<span id="cb11-4"><a href="#cb11-4" tabindex="-1"></a>  </span>
<span id="cb11-5"><a href="#cb11-5" tabindex="-1"></a>  coro<span class="sc">::</span><span class="fu">loop</span>(<span class="cf">for</span> (b <span class="cf">in</span> dl) {</span>
<span id="cb11-6"><a href="#cb11-6" tabindex="-1"></a>    optimizer<span class="sc">$</span><span class="fu">zero_grad</span>()</span>
<span id="cb11-7"><a href="#cb11-7" tabindex="-1"></a>    output <span class="ot">&lt;-</span> <span class="fu">model</span>(b[[<span class="dv">1</span>]])</span>
<span id="cb11-8"><a href="#cb11-8" tabindex="-1"></a>    loss <span class="ot">&lt;-</span> <span class="fu">nnf_nll_loss</span>(output, b[[<span class="dv">2</span>]])</span>
<span id="cb11-9"><a href="#cb11-9" tabindex="-1"></a>    loss<span class="sc">$</span><span class="fu">backward</span>()</span>
<span id="cb11-10"><a href="#cb11-10" tabindex="-1"></a>    optimizer<span class="sc">$</span><span class="fu">step</span>()</span>
<span id="cb11-11"><a href="#cb11-11" tabindex="-1"></a>    l <span class="ot">&lt;-</span> <span class="fu">c</span>(l, loss<span class="sc">$</span><span class="fu">item</span>())</span>
<span id="cb11-12"><a href="#cb11-12" tabindex="-1"></a>  })</span>
<span id="cb11-13"><a href="#cb11-13" tabindex="-1"></a>  </span>
<span id="cb11-14"><a href="#cb11-14" tabindex="-1"></a>  <span class="fu">cat</span>(<span class="fu">sprintf</span>(<span class="st">&quot;Loss at epoch %d: %3f</span><span class="sc">\n</span><span class="st">&quot;</span>, epoch, <span class="fu">mean</span>(l)))</span>
<span id="cb11-15"><a href="#cb11-15" tabindex="-1"></a>}</span>
<span id="cb11-16"><a href="#cb11-16" tabindex="-1"></a><span class="co">#&gt; Loss at epoch 1: 844.674577</span></span>
<span id="cb11-17"><a href="#cb11-17" tabindex="-1"></a><span class="co">#&gt; Loss at epoch 2: 2.068251</span></span>
<span id="cb11-18"><a href="#cb11-18" tabindex="-1"></a><span class="co">#&gt; Loss at epoch 3: 2.068251</span></span>
<span id="cb11-19"><a href="#cb11-19" tabindex="-1"></a><span class="co">#&gt; Loss at epoch 4: 2.068251</span></span>
<span id="cb11-20"><a href="#cb11-20" tabindex="-1"></a><span class="co">#&gt; Loss at epoch 5: 2.068251</span></span>
<span id="cb11-21"><a href="#cb11-21" tabindex="-1"></a><span class="co">#&gt; Loss at epoch 6: 2.068251</span></span>
<span id="cb11-22"><a href="#cb11-22" tabindex="-1"></a><span class="co">#&gt; Loss at epoch 7: 2.068251</span></span>
<span id="cb11-23"><a href="#cb11-23" tabindex="-1"></a><span class="co">#&gt; Loss at epoch 8: 2.068251</span></span>
<span id="cb11-24"><a href="#cb11-24" tabindex="-1"></a><span class="co">#&gt; Loss at epoch 9: 2.068251</span></span>
<span id="cb11-25"><a href="#cb11-25" tabindex="-1"></a><span class="co">#&gt; Loss at epoch 10: 2.068251</span></span></code></pre></div>
<p>Through this example we have trained a deep learning model using
<code>dataset()</code> to define a custom class and then loaded it in
batches with a data loader. By using the dataset and data loader we were
able to write code that split the data preprocessing and setup from the
model training itself.</p>
</div>
</div>
<div id="notes-on-efficiency" class="section level2">
<h2>Notes on efficiency</h2>
<p>When using datasets and data loaders you may find that under certain
conditions your code is running more slowly than you’d expect. In some
situations the overhead of using dataloaders and datasets can impact
overall performance. This may change in time as the R/C++ integration of
Torch improves, but for now there are some workarounds:</p>
<div id="use-.getbatch-instead-of-.getitem" class="section level3">
<h3>Use <code>.getbatch()</code> instead of <code>.getitem()</code></h3>
<p>By default a dataloader will use the <code>.getitem()</code> member
function to pull each single datapoint individually. You can speed this
up by switching to using <code>.getbatch()</code> which will pull all
the datapoints in a batch at once:</p>
<div class="sourceCode" id="cb12"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb12-1"><a href="#cb12-1" tabindex="-1"></a>penguins_dataset_batching <span class="ot">&lt;-</span> <span class="fu">dataset</span>(</span>
<span id="cb12-2"><a href="#cb12-2" tabindex="-1"></a>  </span>
<span id="cb12-3"><a href="#cb12-3" tabindex="-1"></a>  <span class="at">name =</span> <span class="st">&quot;penguins_dataset_batching&quot;</span>,</span>
<span id="cb12-4"><a href="#cb12-4" tabindex="-1"></a>  </span>
<span id="cb12-5"><a href="#cb12-5" tabindex="-1"></a>  <span class="at">initialize =</span> <span class="cf">function</span>() {</span>
<span id="cb12-6"><a href="#cb12-6" tabindex="-1"></a>    self<span class="sc">$</span>data <span class="ot">&lt;-</span> self<span class="sc">$</span><span class="fu">prepare_penguin_data</span>()</span>
<span id="cb12-7"><a href="#cb12-7" tabindex="-1"></a>  },</span>
<span id="cb12-8"><a href="#cb12-8" tabindex="-1"></a>  </span>
<span id="cb12-9"><a href="#cb12-9" tabindex="-1"></a>  <span class="co"># the only change is that this went from .getitem to .getbatch</span></span>
<span id="cb12-10"><a href="#cb12-10" tabindex="-1"></a>  <span class="at">.getbatch =</span> <span class="cf">function</span>(index) {</span>
<span id="cb12-11"><a href="#cb12-11" tabindex="-1"></a>    </span>
<span id="cb12-12"><a href="#cb12-12" tabindex="-1"></a>    x <span class="ot">&lt;-</span> self<span class="sc">$</span>data[index, <span class="dv">2</span><span class="sc">:-</span><span class="dv">1</span>]</span>
<span id="cb12-13"><a href="#cb12-13" tabindex="-1"></a>    y <span class="ot">&lt;-</span> self<span class="sc">$</span>data[index, <span class="dv">1</span>]<span class="sc">$</span><span class="fu">to</span>(<span class="fu">torch_long</span>())</span>
<span id="cb12-14"><a href="#cb12-14" tabindex="-1"></a>    </span>
<span id="cb12-15"><a href="#cb12-15" tabindex="-1"></a>    <span class="fu">list</span>(x, y)</span>
<span id="cb12-16"><a href="#cb12-16" tabindex="-1"></a>  },</span>
<span id="cb12-17"><a href="#cb12-17" tabindex="-1"></a>  </span>
<span id="cb12-18"><a href="#cb12-18" tabindex="-1"></a>  <span class="at">.length =</span> <span class="cf">function</span>() {</span>
<span id="cb12-19"><a href="#cb12-19" tabindex="-1"></a>    self<span class="sc">$</span>data<span class="sc">$</span><span class="fu">size</span>()[[<span class="dv">1</span>]]</span>
<span id="cb12-20"><a href="#cb12-20" tabindex="-1"></a>  },</span>
<span id="cb12-21"><a href="#cb12-21" tabindex="-1"></a>  </span>
<span id="cb12-22"><a href="#cb12-22" tabindex="-1"></a>  <span class="at">prepare_penguin_data =</span> <span class="cf">function</span>() {</span>
<span id="cb12-23"><a href="#cb12-23" tabindex="-1"></a>    </span>
<span id="cb12-24"><a href="#cb12-24" tabindex="-1"></a>    input <span class="ot">&lt;-</span> <span class="fu">na.omit</span>(penguins) </span>
<span id="cb12-25"><a href="#cb12-25" tabindex="-1"></a>    <span class="co"># conveniently, the categorical data are already factors</span></span>
<span id="cb12-26"><a href="#cb12-26" tabindex="-1"></a>    input<span class="sc">$</span>species <span class="ot">&lt;-</span> <span class="fu">as.numeric</span>(input<span class="sc">$</span>species)</span>
<span id="cb12-27"><a href="#cb12-27" tabindex="-1"></a>    input<span class="sc">$</span>island <span class="ot">&lt;-</span> <span class="fu">as.numeric</span>(input<span class="sc">$</span>island)</span>
<span id="cb12-28"><a href="#cb12-28" tabindex="-1"></a>    input<span class="sc">$</span>sex <span class="ot">&lt;-</span> <span class="fu">as.numeric</span>(input<span class="sc">$</span>sex)</span>
<span id="cb12-29"><a href="#cb12-29" tabindex="-1"></a>    </span>
<span id="cb12-30"><a href="#cb12-30" tabindex="-1"></a>    input <span class="ot">&lt;-</span> <span class="fu">as.matrix</span>(input)</span>
<span id="cb12-31"><a href="#cb12-31" tabindex="-1"></a>    <span class="fu">torch_tensor</span>(input)</span>
<span id="cb12-32"><a href="#cb12-32" tabindex="-1"></a>  }</span>
<span id="cb12-33"><a href="#cb12-33" tabindex="-1"></a>)</span></code></pre></div>
<p>In many instances the only change is to exactly replace just
<code>.getitem</code> with <code>.getbatch</code> since often the
<code>.getitem</code> function is written to handle vectors of indices.
In this penguins example the <code>.getitem</code> function used the
index to select the rows, which will work fine with a vector instead</p>
</div>
<div id="remove-dataset-dataloader-and-manually-define-the-function-calls" class="section level3">
<h3>Remove dataset dataloader and manually define the function
calls</h3>
<p>If switching to <code>.getbatch</code> does not provide the benefit
you were expecting you could also remove the <code>dataset</code>
entirely and manually pass the data. At this point you are trading
readability of your code and convenience for speed.</p>
<div class="sourceCode" id="cb13"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb13-1"><a href="#cb13-1" tabindex="-1"></a>input <span class="ot">&lt;-</span> <span class="fu">na.omit</span>(penguins) </span>
<span id="cb13-2"><a href="#cb13-2" tabindex="-1"></a><span class="co"># conveniently, the categorical data are already factors</span></span>
<span id="cb13-3"><a href="#cb13-3" tabindex="-1"></a>input<span class="sc">$</span>species <span class="ot">&lt;-</span> <span class="fu">as.numeric</span>(input<span class="sc">$</span>species)</span>
<span id="cb13-4"><a href="#cb13-4" tabindex="-1"></a>input<span class="sc">$</span>island <span class="ot">&lt;-</span> <span class="fu">as.numeric</span>(input<span class="sc">$</span>island)</span>
<span id="cb13-5"><a href="#cb13-5" tabindex="-1"></a>input<span class="sc">$</span>sex <span class="ot">&lt;-</span> <span class="fu">as.numeric</span>(input<span class="sc">$</span>sex)</span>
<span id="cb13-6"><a href="#cb13-6" tabindex="-1"></a></span>
<span id="cb13-7"><a href="#cb13-7" tabindex="-1"></a>input <span class="ot">&lt;-</span> <span class="fu">as.matrix</span>(input)</span>
<span id="cb13-8"><a href="#cb13-8" tabindex="-1"></a>input <span class="ot">&lt;-</span> <span class="fu">torch_tensor</span>(input)</span>
<span id="cb13-9"><a href="#cb13-9" tabindex="-1"></a></span>
<span id="cb13-10"><a href="#cb13-10" tabindex="-1"></a>data_x <span class="ot">&lt;-</span> input[, <span class="dv">2</span><span class="sc">:-</span><span class="dv">1</span>]</span>
<span id="cb13-11"><a href="#cb13-11" tabindex="-1"></a>data_y <span class="ot">&lt;-</span> input[, <span class="dv">1</span>]<span class="sc">$</span><span class="fu">to</span>(<span class="fu">torch_long</span>())</span>
<span id="cb13-12"><a href="#cb13-12" tabindex="-1"></a></span>
<span id="cb13-13"><a href="#cb13-13" tabindex="-1"></a>batch_size <span class="ot">&lt;-</span> <span class="dv">8</span></span>
<span id="cb13-14"><a href="#cb13-14" tabindex="-1"></a>num_data_points <span class="ot">&lt;-</span> data_y<span class="sc">$</span><span class="fu">size</span>(<span class="dv">1</span>)</span>
<span id="cb13-15"><a href="#cb13-15" tabindex="-1"></a>num_batches <span class="ot">&lt;-</span> <span class="fu">floor</span>(num_data_points<span class="sc">/</span>batch_size)</span>
<span id="cb13-16"><a href="#cb13-16" tabindex="-1"></a></span>
<span id="cb13-17"><a href="#cb13-17" tabindex="-1"></a><span class="cf">for</span>(epoch <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">10</span>){</span>
<span id="cb13-18"><a href="#cb13-18" tabindex="-1"></a></span>
<span id="cb13-19"><a href="#cb13-19" tabindex="-1"></a>  <span class="co"># rearrange the data each epoch</span></span>
<span id="cb13-20"><a href="#cb13-20" tabindex="-1"></a>  permute <span class="ot">&lt;-</span> <span class="fu">torch_randperm</span>(num_data_points) <span class="sc">+</span> <span class="dv">1</span><span class="dt">L</span></span>
<span id="cb13-21"><a href="#cb13-21" tabindex="-1"></a>  data_x <span class="ot">&lt;-</span> data_x[permute]</span>
<span id="cb13-22"><a href="#cb13-22" tabindex="-1"></a>  data_y <span class="ot">&lt;-</span> data_y[permute]</span>
<span id="cb13-23"><a href="#cb13-23" tabindex="-1"></a>  </span>
<span id="cb13-24"><a href="#cb13-24" tabindex="-1"></a>  <span class="co"># manually loop through the batches</span></span>
<span id="cb13-25"><a href="#cb13-25" tabindex="-1"></a>  <span class="cf">for</span>(batch_idx <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>num_batches){</span>
<span id="cb13-26"><a href="#cb13-26" tabindex="-1"></a></span>
<span id="cb13-27"><a href="#cb13-27" tabindex="-1"></a>    <span class="co"># here index is a vector of the indices in the batch</span></span>
<span id="cb13-28"><a href="#cb13-28" tabindex="-1"></a>    index <span class="ot">&lt;-</span> (batch_size<span class="sc">*</span>(batch_idx<span class="dv">-1</span>) <span class="sc">+</span> <span class="dv">1</span>)<span class="sc">:</span>(batch_idx<span class="sc">*</span>batch_size)</span>
<span id="cb13-29"><a href="#cb13-29" tabindex="-1"></a>    </span>
<span id="cb13-30"><a href="#cb13-30" tabindex="-1"></a>    x <span class="ot">&lt;-</span> data_x[index]</span>
<span id="cb13-31"><a href="#cb13-31" tabindex="-1"></a>    y <span class="ot">&lt;-</span> data_y[index]<span class="sc">$</span><span class="fu">to</span>(<span class="fu">torch_long</span>())</span>
<span id="cb13-32"><a href="#cb13-32" tabindex="-1"></a></span>
<span id="cb13-33"><a href="#cb13-33" tabindex="-1"></a>    optimizer<span class="sc">$</span><span class="fu">zero_grad</span>()</span>
<span id="cb13-34"><a href="#cb13-34" tabindex="-1"></a>    output <span class="ot">&lt;-</span> <span class="fu">model</span>(x)</span>
<span id="cb13-35"><a href="#cb13-35" tabindex="-1"></a>    loss <span class="ot">&lt;-</span> <span class="fu">nnf_nll_loss</span>(output, y)</span>
<span id="cb13-36"><a href="#cb13-36" tabindex="-1"></a>    loss<span class="sc">$</span><span class="fu">backward</span>()</span>
<span id="cb13-37"><a href="#cb13-37" tabindex="-1"></a>    optimizer<span class="sc">$</span><span class="fu">step</span>()</span>
<span id="cb13-38"><a href="#cb13-38" tabindex="-1"></a>    l <span class="ot">&lt;-</span> <span class="fu">c</span>(l, loss<span class="sc">$</span><span class="fu">item</span>())</span>
<span id="cb13-39"><a href="#cb13-39" tabindex="-1"></a>  }</span>
<span id="cb13-40"><a href="#cb13-40" tabindex="-1"></a>  </span>
<span id="cb13-41"><a href="#cb13-41" tabindex="-1"></a>  <span class="fu">cat</span>(<span class="fu">sprintf</span>(<span class="st">&quot;Loss at epoch %d: %3f</span><span class="sc">\n</span><span class="st">&quot;</span>, epoch, <span class="fu">mean</span>(l)))</span>
<span id="cb13-42"><a href="#cb13-42" tabindex="-1"></a>}</span></code></pre></div>
</div>
</div>



<!-- code folding -->


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
